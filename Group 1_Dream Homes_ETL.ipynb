{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13079296-0531-474e-bfe8-e6a06bb55e64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "13079296-0531-474e-bfe8-e6a06bb55e64",
    "outputId": "e3e327ec-0b81-47a0-d340-f4b228ee888d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (38.0.0)\n",
      "Requirement already satisfied: tzdata in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from faker) (2025.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install faker\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "import random\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "\n",
    "# we use Faker because it creates realistic synthetic data\n",
    "# and supports controlled randomness for business logic.\n",
    "fake = Faker()\n",
    "\n",
    "# seeds are important here to ensure identical results\n",
    "# across machines and keep debugging consistent.\n",
    "random.seed(42)\n",
    "Faker.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7GAqEv2z_0F1",
   "metadata": {
    "id": "7GAqEv2z_0F1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: 1\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\"postgresql://indangayusafitrie:password@localhost:5432/dream_homes_nyc\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(\"OK:\", conn.scalar(text(\"SELECT 1\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b1e559b-7580-4f8f-8297-94e0afd11b11",
   "metadata": {
    "id": "4b1e559b-7580-4f8f-8297-94e0afd11b11"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "ddl = \"\"\"\n",
    "DROP TABLE IF EXISTS\n",
    "    Commissions,\n",
    "    Customer_Interactions,\n",
    "    Contracts,\n",
    "    Offers,\n",
    "    Leads,\n",
    "    Customers,\n",
    "    Property_Price_History,\n",
    "    Listings,\n",
    "    Properties,\n",
    "    Schools,\n",
    "    Neighborhoods,\n",
    "    Agents,\n",
    "    Teams,\n",
    "    Offices\n",
    "CASCADE;\n",
    "\n",
    "/* CORPORATE OFFICE CATEGORY */\n",
    "/* Create Offices first (no dependencies) */\n",
    "CREATE TABLE Offices (\n",
    "    office_id SERIAL PRIMARY KEY,\n",
    "    office_name VARCHAR(100) NOT NULL,\n",
    "    address VARCHAR(255) NOT NULL,\n",
    "    city VARCHAR(100) NOT NULL,\n",
    "    state VARCHAR(2) NOT NULL CHECK (state IN ('NY', 'NJ', 'CT')),\n",
    "    zip_code VARCHAR(10) NOT NULL,\n",
    "    phone VARCHAR(20)\n",
    ");\n",
    "\n",
    "/* Create Teams after Offices */\n",
    "CREATE TABLE Teams (\n",
    "    team_id SERIAL PRIMARY KEY,\n",
    "    team_name VARCHAR(100) NOT NULL,\n",
    "    team_lead_id INTEGER,\n",
    "    office_id INTEGER REFERENCES Offices(office_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    established_date DATE,\n",
    "    region VARCHAR(20)\n",
    ");\n",
    "\n",
    "/* Create Agents after Offices and Teams */\n",
    "CREATE TABLE Agents (\n",
    "    agent_id SERIAL PRIMARY KEY,\n",
    "    office_id INTEGER REFERENCES Offices(office_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    team_id INTEGER REFERENCES Teams(team_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    first_name VARCHAR(50) NOT NULL,\n",
    "    last_name VARCHAR(50) NOT NULL,\n",
    "    email VARCHAR(100) UNIQUE NOT NULL,\n",
    "    phone VARCHAR(20),\n",
    "    license_number VARCHAR(50) UNIQUE NOT NULL,\n",
    "    hire_date DATE NOT NULL,\n",
    "    status VARCHAR(20) CHECK (status IN ('Active', 'Inactive', 'Retired')),\n",
    "    commission_tier VARCHAR(50)\n",
    ");\n",
    "\n",
    "/* Create Commissions after Agents */\n",
    "CREATE TABLE Commissions (\n",
    "    commission_id SERIAL PRIMARY KEY,\n",
    "    transaction_id INTEGER,\n",
    "    agent_id INTEGER NOT NULL REFERENCES Agents(agent_id) ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "    team_id INTEGER REFERENCES Teams(team_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    office_id INTEGER REFERENCES Offices(office_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    commission_amount NUMERIC(12,2) CHECK (commission_amount >= 0),\n",
    "    commission_rate NUMERIC(5,2) CHECK (commission_rate BETWEEN 0 AND 100),\n",
    "    commission_type VARCHAR(20) CHECK (commission_type IN ('Buyer', 'Seller')),\n",
    "    split_percentage NUMERIC(5,2),\n",
    "    paid_date DATE,\n",
    "    status VARCHAR(20) CHECK (status IN ('pending', 'paid', 'disputed'))\n",
    ");\n",
    "\n",
    "\n",
    "/* INVENTORY CATEGORY */\n",
    "/* Create Neighborhoods first (no dependencies) */\n",
    "CREATE TABLE Neighborhoods (\n",
    "    neighborhood_id SERIAL PRIMARY KEY,\n",
    "    neighborhood_name VARCHAR(120) NOT NULL,\n",
    "    city VARCHAR(120) NOT NULL,\n",
    "    state VARCHAR(2) NOT NULL CHECK (state IN ('NY', 'NJ', 'CT')),\n",
    "    zip_code VARCHAR(10) NOT NULL,\n",
    "    walkability_score INTEGER CHECK (walkability_score BETWEEN 0 AND 100),\n",
    "    UNIQUE (neighborhood_name, city, state, zip_code)\n",
    ");\n",
    "\n",
    "/* Create Schools after Neighborhoods */\n",
    "CREATE TABLE Schools (\n",
    "    school_id SERIAL PRIMARY KEY,\n",
    "    school_name VARCHAR(160) NOT NULL,\n",
    "    grade_level VARCHAR(20) NOT NULL CHECK (grade_level IN ('Elementary', 'Middle', 'High', 'K12', 'Other')),\n",
    "    school_rating VARCHAR(1) CHECK (school_rating IN ('A','B','C')),\n",
    "    neighborhood_id INTEGER REFERENCES Neighborhoods(neighborhood_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    address VARCHAR(240)\n",
    ");\n",
    "\n",
    "/* Create Properties after Neighborhoods */\n",
    "CREATE TABLE Properties (\n",
    "    property_id SERIAL PRIMARY KEY,\n",
    "    address VARCHAR(240) NOT NULL,\n",
    "    neighborhood_id INTEGER REFERENCES Neighborhoods(neighborhood_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    property_type VARCHAR(40) NOT NULL CHECK (property_type IN ('Single-family', 'Condo', 'Townhouse', 'Multi-unit')),\n",
    "    rooms NUMERIC(2,1) NOT NULL,\n",
    "    bedroom NUMERIC(2,1) NOT NULL,\n",
    "    bathroom NUMERIC(2,1) NOT NULL,\n",
    "    sqft INTEGER CHECK (sqft > 0),\n",
    "    price NUMERIC(14,2) CHECK (price >= 0)\n",
    ");\n",
    "\n",
    "/* Create Listings after Properties and Agents */\n",
    "CREATE TABLE Listings (\n",
    "    listing_id SERIAL PRIMARY KEY,\n",
    "    property_id INTEGER NOT NULL REFERENCES Properties(property_id) ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "    agent_id INTEGER REFERENCES Agents(agent_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    listing_type VARCHAR(10) NOT NULL CHECK (listing_type IN ('Sale', 'Rent')),\n",
    "    listing_date DATE NOT NULL,\n",
    "    listing_price NUMERIC(14,2) CHECK (listing_price >= 0),\n",
    "    listing_status VARCHAR(20) NOT NULL CHECK (listing_status IN ('Active', 'Pending', 'Sold', 'Rented', 'Expired', 'Withdrawn')),\n",
    "    close_date DATE,\n",
    "    last_updated TIMESTAMP DEFAULT NOW(),\n",
    "    CONSTRAINT chk_listing_dates CHECK (close_date IS NULL OR close_date >= listing_date)\n",
    ");\n",
    "\n",
    "/* Create Property_Price_History after Listings */\n",
    "CREATE TABLE Property_Price_History (\n",
    "    price_history_id SERIAL PRIMARY KEY,\n",
    "    listing_id INTEGER NOT NULL REFERENCES Listings(listing_id) ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "    old_price NUMERIC(14,2) CHECK (old_price >= 0),\n",
    "    new_price NUMERIC(14,2) CHECK (new_price >= 0),\n",
    "    change_date TIMESTAMP DEFAULT NOW(),\n",
    "    reason_for_change VARCHAR(160),\n",
    "    CONSTRAINT chk_price_change CHECK (old_price IS NULL OR new_price <> old_price)\n",
    ");\n",
    "\n",
    "\n",
    "/* CUSTOMERS CATEGORY */\n",
    "/* Create Customers first (no dependencies) */\n",
    "CREATE TABLE Customers (\n",
    "    customer_id SERIAL PRIMARY KEY,\n",
    "    first_name VARCHAR(50) NOT NULL,\n",
    "    last_name VARCHAR(50) NOT NULL,\n",
    "    email VARCHAR(100) UNIQUE,\n",
    "    phone VARCHAR(20),\n",
    "    address VARCHAR(255),\n",
    "    customer_type VARCHAR(10) NOT NULL CHECK (customer_type IN ('buyer','seller','renter')),\n",
    "    created_date DATE NOT NULL DEFAULT CURRENT_DATE,\n",
    "    updated_date DATE\n",
    ");\n",
    "\n",
    "/* Create Leads after Customers */\n",
    "CREATE TABLE Leads (\n",
    "    lead_id SERIAL PRIMARY KEY,\n",
    "    customer_id INTEGER NOT NULL REFERENCES Customers(customer_id) ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "    lead_date DATE NOT NULL,\n",
    "    lead_source VARCHAR(20) CHECK (lead_source IN ('email','digital','print','event','referral','cold_call')),\n",
    "    lead_status VARCHAR(10) NOT NULL CHECK (lead_status IN ('active','converted','lost','archived')),\n",
    "    est_value NUMERIC(12,2),\n",
    "    notes TEXT\n",
    ");\n",
    "\n",
    "/* Create Customer_Interactions after Customers and Leads */\n",
    "CREATE TABLE Customer_Interactions (\n",
    "    interaction_id SERIAL PRIMARY KEY,\n",
    "    customer_id INTEGER NOT NULL REFERENCES Customers(customer_id) ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "    lead_id INTEGER REFERENCES Leads(lead_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    interaction_dt TIMESTAMP NOT NULL DEFAULT NOW(),\n",
    "    channel VARCHAR(15) CHECK (channel IN ('call','email','text','meeting','showing','other')),\n",
    "    subject VARCHAR(120),\n",
    "    details TEXT,\n",
    "    listing_id INTEGER REFERENCES Listings(listing_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    outcome VARCHAR(20)\n",
    ");\n",
    "\n",
    "/* Create Offers after Customers and Listings (and optionally Agents) */\n",
    "CREATE TABLE Offers (\n",
    "    offer_id SERIAL PRIMARY KEY,\n",
    "    customer_id INTEGER NOT NULL REFERENCES Customers(customer_id) ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "    listing_id INTEGER NOT NULL REFERENCES Listings(listing_id) ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "    agent_id INTEGER REFERENCES Agents(agent_id) ON UPDATE CASCADE ON DELETE SET NULL,\n",
    "    offer_price NUMERIC(12,2) NOT NULL CHECK (offer_price > 0),\n",
    "    offer_date DATE NOT NULL,\n",
    "    status VARCHAR(16) NOT NULL CHECK (status IN ('submitted','counter','accepted','rejected','expired')),\n",
    "    contingencies TEXT\n",
    ");\n",
    "\n",
    "/* Create Contracts after Offers */\n",
    "CREATE TABLE Contracts (\n",
    "    contract_id SERIAL PRIMARY KEY,\n",
    "    offer_id INTEGER NOT NULL UNIQUE REFERENCES Offers(offer_id) ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "    contract_type VARCHAR(10) NOT NULL CHECK (contract_type IN ('purchase','lease','listing')),\n",
    "    contract_date DATE NOT NULL,\n",
    "    expected_close_date DATE,\n",
    "    signed_date DATE,\n",
    "    contract_status VARCHAR(12) NOT NULL CHECK (contract_status IN ('pending','active','closed','expired','terminated')),\n",
    "    terms TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(ddl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Pg6p1sW9t9BF",
   "metadata": {
    "id": "Pg6p1sW9t9BF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OFFICES (5–8 rows)\n",
    "\n",
    "offices = []\n",
    "for _ in range(random.randint(5, 8)):\n",
    "    state = random.choice(['NY','NJ','CT'])\n",
    "    offices.append({\n",
    "        # office name is generated using the city name to help keep names unique\n",
    "        \"office_name\": f\"Dream Homes {fake.city()} Office\",\n",
    "        \"address\": fake.street_address(),\n",
    "        \"city\": fake.city(),\n",
    "        # state is selected randomly for simple geographic variety\n",
    "        \"state\": state,\n",
    "        \"zip_code\": fake.zipcode(),\n",
    "        # phone trimmed to 20 chars to fit schema limit\n",
    "        \"phone\": re.sub(r\"[^0-9+()-]\", \"\", fake.phone_number())[:20],\n",
    "    })\n",
    "\n",
    "df_offices = pd.DataFrame(offices)\n",
    "\n",
    "# SQL insertion to generate office_id automatically from SERIAL\n",
    "df_offices.to_sql(\"offices\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47jjDTUq_DO8",
   "metadata": {
    "id": "47jjDTUq_DO8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we recall the IDs that will be used for FK in this table\n",
    "# to ensure we're using adjacent IDs and it will be present\n",
    "# in the other tables.\n",
    "\n",
    "# TEAMS FK Data Insertion\n",
    "\n",
    "df_offices_db = pd.read_sql(\n",
    "    \"SELECT office_id FROM offices ORDER BY office_id\",\n",
    "    engine\n",
    ")\n",
    "office_ids = df_offices_db[\"office_id\"].tolist()\n",
    "\n",
    "# TEAMS (10–15 rows)\n",
    "\n",
    "teams = []\n",
    "for _ in range(random.randint(10, 15)):\n",
    "    teams.append({\n",
    "        # team name uses a random last name to make each team easy to differentiate\n",
    "        \"team_name\": f\"{fake.last_name()} Group\",\n",
    "        # office_id is pulled from the existing offices table for FK consistency\n",
    "        \"office_id\": random.choice(office_ids),\n",
    "        # established_date pulled from within the past 5 years to keep data seemingly relevant\n",
    "        \"established_date\": fake.date_between(start_date=\"-5y\", end_date=\"today\"),\n",
    "        \"region\": random.choice(['NY','NJ','CT'])\n",
    "    })\n",
    "\n",
    "df_teams = pd.DataFrame(teams)\n",
    "\n",
    "# SQL insertion to generate team_id automatically from SERIAL\n",
    "df_teams.to_sql(\"teams\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oXmm5V9P_HNC",
   "metadata": {
    "id": "oXmm5V9P_HNC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AGENTS FK Data Insertion\n",
    "\n",
    "df_teams_db = pd.read_sql(\n",
    "    \"SELECT team_id, office_id FROM teams ORDER BY team_id\",\n",
    "    engine\n",
    ")\n",
    "team_ids = df_teams_db[\"team_id\"].tolist()\n",
    "\n",
    "# AGENTS (40–60 rows)\n",
    "\n",
    "agents = []\n",
    "for _ in range(random.randint(40, 60)):\n",
    "    \n",
    "    # sample a team row so agent inherits the correct office + team pairing\n",
    "    team_row = df_teams_db.sample(1).iloc[0]\n",
    "    office_id_val = int(team_row[\"office_id\"])\n",
    "    team_id_val = int(team_row[\"team_id\"])\n",
    "\n",
    "    agents.append({\n",
    "        # office_id taken from the team’s real office for logical consistency\n",
    "        \"office_id\": office_id_val,\n",
    "        # team_id also matched with the selected team\n",
    "        \"team_id\": team_id_val,\n",
    "        \"first_name\": fake.first_name(),\n",
    "        \"last_name\": fake.last_name(),\n",
    "        \"email\": fake.unique.email(),\n",
    "        \"phone\": re.sub(r\"[^0-9+()-]\", \"\", fake.phone_number())[:20],\n",
    "        \"license_number\": fake.unique.bothify(\"LIC-#####\"),\n",
    "        # hire dates chosen within the last 6 years to mimic realistic tenure\n",
    "        \"hire_date\": fake.date_between(start_date=\"-6y\", end_date=\"today\"),\n",
    "        \"status\": random.choice([\"Active\", \"Inactive\", \"Retired\"]),\n",
    "        \"commission_tier\": random.choice([\"Standard\", \"Premium\", \"Executive\"])\n",
    "    })\n",
    "\n",
    "df_agents = pd.DataFrame(agents)\n",
    "\n",
    "# SQL insertion to generate agent_id automatically from SERIAL\n",
    "df_agents.to_sql(\"agents\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7J-PjJ9P_IyV",
   "metadata": {
    "id": "7J-PjJ9P_IyV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMMISSIONS FK Data Insertion\n",
    "\n",
    "df_agents_db = pd.read_sql(\n",
    "    \"SELECT agent_id, team_id, office_id FROM agents ORDER BY agent_id\",\n",
    "    engine\n",
    ")\n",
    "agent_ids = df_agents_db[\"agent_id\"].tolist()\n",
    "\n",
    "# COMMISSIONS (80–120 rows)\n",
    "\n",
    "commissions = []\n",
    "for _ in range(random.randint(80, 120)):\n",
    "    # sample a single agent so we can reuse their team and office info\n",
    "    agent_row = df_agents_db.sample(1).iloc[0]\n",
    "\n",
    "    # convert nullable FKs safely to Python None if needed\n",
    "    agent_id_val = int(agent_row[\"agent_id\"])\n",
    "    team_id_val = int(agent_row[\"team_id\"]) if pd.notna(agent_row[\"team_id\"]) else None\n",
    "    office_id_val = int(agent_row[\"office_id\"]) if pd.notna(agent_row[\"office_id\"]) else None\n",
    "\n",
    "    commissions.append({\n",
    "        \"transaction_id\": random.randint(1, 200),\n",
    "        # agent_id pulled directly from existing agents to maintain FK validity\n",
    "        \"agent_id\": agent_id_val,\n",
    "        # team_id and office_id tied to the agent's actual team and office\n",
    "        \"team_id\": team_id_val,\n",
    "        \"office_id\": office_id_val,\n",
    "        # we use 1,000–15,000 to keep commissions realistic\n",
    "        # small rentals may generate 1–3K, mid-range sales 5–15K\n",
    "        \"commission_amount\": round(random.uniform(1000, 15000), 2),\n",
    "        # typical broker fees fall around 2.5–3 percent\n",
    "        # using 1–6 percent covers discount, standard, and premium scenarios\n",
    "        \"commission_rate\": round(random.uniform(1, 6), 2),\n",
    "        \"commission_type\": random.choice([\"Buyer\", \"Seller\"]),\n",
    "        # split range allows 0 percent (agent keeps all) up to 50 percent (team-heavy structure)\n",
    "        \"split_percentage\": round(random.uniform(0, 50), 2),\n",
    "        # paid_date chosen within the past year to mimic recent activity\n",
    "        \"paid_date\": fake.date_between(start_date=\"-1y\", end_date=\"today\"),\n",
    "        \"status\": random.choice([\"pending\", \"paid\", \"disputed\"])\n",
    "    })\n",
    "\n",
    "df_commissions = pd.DataFrame(commissions)\n",
    "\n",
    "# SQL insertion to generate commission_id automatically from SERIAL\n",
    "df_commissions.to_sql(\"commissions\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3481ff5e-2908-40f0-9574-0224b987625a",
   "metadata": {
    "id": "3481ff5e-2908-40f0-9574-0224b987625a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEIGHBORHOODS (10–15 rows)\n",
    "\n",
    "neighborhoods = []\n",
    "for _ in range(random.randint(10, 20)):\n",
    "    state = random.choice(['NY', 'NJ', 'CT'])\n",
    "    neighborhoods.append({\n",
    "        \"neighborhood_name\": fake.city(),\n",
    "        \"city\": fake.city(),\n",
    "        \"state\": state,\n",
    "        \"zip_code\": fake.zipcode(),\n",
    "        # walkability_score manually set between 40–100 to allow both\n",
    "        # car-dependent and highly walkable neighborhoods for analysis\n",
    "        \"walkability_score\": random.randint(40, 100)\n",
    "    })\n",
    "\n",
    "df_neighborhoods = pd.DataFrame(neighborhoods)\n",
    "\n",
    "# SQL insertion to generate neighborhood_id automatically from SERIAL\n",
    "df_neighborhoods.to_sql(\"neighborhoods\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ImZGc5aH_Ki5",
   "metadata": {
    "id": "ImZGc5aH_Ki5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SCHOOLS FK Data Insertion\n",
    "\n",
    "df_neighborhoods_db = pd.read_sql(\n",
    "    \"SELECT neighborhood_id FROM neighborhoods ORDER BY neighborhood_id\",\n",
    "    engine\n",
    ")\n",
    "neighborhood_ids = df_neighborhoods_db[\"neighborhood_id\"].tolist()\n",
    "\n",
    "# SCHOOLS (20-30 rows)\n",
    "\n",
    "# grade_level chosen from standard school categories\n",
    "grade_levels = [\"Elementary\", \"Middle\", \"High\", \"K12\", \"Other\"]\n",
    "# rating uses A–C to support “Grade A schools” analysis later\n",
    "ratings = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "schools = []\n",
    "for _ in range(random.randint(15, 30)):\n",
    "    schools.append({\n",
    "        # school_name combines a company-like name with common school suffixes\n",
    "        # to create realistic institution names\n",
    "        \"school_name\": fake.company() + \" \" + random.choice([\"Academy\", \"Prep\", \"School\", \"Charter\"]),\n",
    "        \"grade_level\": random.choice(grade_levels),\n",
    "        \"school_rating\": random.choice(ratings),\n",
    "        # neighborhood_id selected from existing neighborhoods for FK alignment\n",
    "        \"neighborhood_id\": random.choice(neighborhood_ids),\n",
    "        \"address\": fake.street_address()\n",
    "    })\n",
    "\n",
    "df_schools = pd.DataFrame(schools)\n",
    "\n",
    "# SQL insertion to generate school_id automatically from SERIAL\n",
    "df_schools.to_sql(\"schools\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8_ZpxYCB_MTF",
   "metadata": {
    "id": "8_ZpxYCB_MTF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PROPERTIES FK Data Insertion\n",
    "\n",
    "df_neighborhoods_db = pd.read_sql(\n",
    "    \"SELECT neighborhood_id FROM neighborhoods ORDER BY neighborhood_id\",\n",
    "    engine\n",
    ")\n",
    "neighborhood_ids = df_neighborhoods_db[\"neighborhood_id\"].tolist()\n",
    "\n",
    "# PROPERTIES FK Data Insertion\n",
    "\n",
    "df_neighborhoods_db = pd.read_sql(\n",
    "    \"SELECT neighborhood_id FROM neighborhoods ORDER BY neighborhood_id\",\n",
    "    engine\n",
    ")\n",
    "neighborhood_ids = df_neighborhoods_db[\"neighborhood_id\"].tolist()\n",
    "\n",
    "# PROPERTIES (150-250 rows)\n",
    "\n",
    "property_types = [\"Single-family\", \"Condo\", \"Townhouse\", \"Multi-unit\"]\n",
    "\n",
    "properties = []\n",
    "for _ in range(random.randint(40, 70)):\n",
    "    \n",
    "    p_type = random.choice(property_types)\n",
    "\n",
    "    # separating sale prices vs rent prices\n",
    "    # because the two have different price ranges\n",
    "    if p_type == \"Multi-unit\":\n",
    "        # rental-style price range (monthly rent)\n",
    "        price_val = round(random.uniform(1500, 8000), 2)\n",
    "    else:\n",
    "        # sale-style price range\n",
    "        price_val = round(random.uniform(200000, 3500000), 2)\n",
    "        \n",
    "    # rooms must stay under 10.0 to fit NUMERIC(2,1) (max 9.9)\n",
    "    rooms_val = round(random.uniform(3, 9.9), 1)\n",
    "    bedroom_val = round(random.uniform(1, 5), 1)\n",
    "    bathroom_val = round(random.uniform(1, 4), 1)\n",
    "\n",
    "    properties.append({\n",
    "        \"address\": fake.street_address(),\n",
    "        # neighborhood_id pulled from existing neighborhoods for FK alignment\n",
    "        \"neighborhood_id\": random.choice(neighborhood_ids),\n",
    "        # property_type uses the same p_type used for pricing logic\n",
    "        \"property_type\": p_type,\n",
    "        # rooms/bed/bath use float values to resemble real listing specs\n",
    "        # but all kept < 10.0 to satisfy NUMERIC(2,1)\n",
    "        \"rooms\": rooms_val,\n",
    "        \"bedroom\": bedroom_val,\n",
    "        \"bathroom\": bathroom_val,\n",
    "        # sqft uses 450–4200 to capture NYC studio sizes up to large homes\n",
    "        \"sqft\": random.randint(450, 4200),\n",
    "        # price depends on whether the property is rental or sale\n",
    "        \"price\": price_val\n",
    "    })\n",
    "\n",
    "df_properties = pd.DataFrame(properties)\n",
    "\n",
    "# SQL insertion to generate property_id automatically from SERIAL\n",
    "df_properties.to_sql(\"properties\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "YMQya-cS_OP4",
   "metadata": {
    "id": "YMQya-cS_OP4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LISTING FK Data Insertion\n",
    "\n",
    "df_properties_db = pd.read_sql(\n",
    "    \"SELECT property_id, price, property_type FROM properties ORDER BY property_id\",\n",
    "    engine\n",
    ")\n",
    "property_ids = df_properties_db[\"property_id\"].tolist()\n",
    "\n",
    "df_agents_db = pd.read_sql(\n",
    "    \"SELECT agent_id FROM agents ORDER BY agent_id\",\n",
    "    engine\n",
    ")\n",
    "agent_ids = df_agents_db[\"agent_id\"].tolist()\n",
    "\n",
    "# LISTING (200-350 rows)\n",
    "\n",
    "listings = []\n",
    "for _ in range(random.randint(200, 350)):\n",
    "\n",
    "    # sample an existing property to anchor FK and pricing logic\n",
    "    prop_row = df_properties_db.sample(1).iloc[0]\n",
    "    base_price = float(prop_row[\"price\"])\n",
    "    p_type = prop_row[\"property_type\"]\n",
    "\n",
    "    # multi-unit properties are more likely rentals, others more likely sales\n",
    "    if p_type == \"Multi-unit\":\n",
    "        listing_type = \"Rent\"\n",
    "    else:\n",
    "        listing_type = \"Sale\"\n",
    "\n",
    "    # price factor depends on listing type:\n",
    "    # sale: +-10–25%, rent: +-5–15%\n",
    "    if listing_type == \"Sale\":\n",
    "        factor = random.uniform(0.90, 1.25)\n",
    "    else:\n",
    "        factor = random.uniform(0.85, 1.15)\n",
    "\n",
    "    listing_price = round(base_price * factor, 2)\n",
    "\n",
    "    # listing_date is kept within the last 2 years to maintain relevance\n",
    "    listing_date = fake.date_between(start_date=\"-2y\", end_date=\"today\")\n",
    "\n",
    "    # optional close_date, 40% chance to simulate listings that successfully close\n",
    "    # leaves ~60% of listings still in inventory\n",
    "    if random.random() < 0.4:\n",
    "        close_date = fake.date_between(start_date=listing_date, end_date=\"today\")\n",
    "    else:\n",
    "        close_date = None\n",
    "\n",
    "    # status pool adjusted so sale listings don't use \"Rented\" and rentals do\n",
    "    if listing_type == \"Sale\":\n",
    "        status_pool = [\"Active\", \"Pending\", \"Sold\", \"Expired\", \"Withdrawn\"]\n",
    "    else:\n",
    "        status_pool = [\"Active\", \"Pending\", \"Rented\", \"Expired\", \"Withdrawn\"]\n",
    "\n",
    "    listings.append({\n",
    "        # property_id pulled from existing properties\n",
    "        \"property_id\": int(prop_row[\"property_id\"]),\n",
    "        # agent_id chosen from existing agents\n",
    "        \"agent_id\": random.choice(agent_ids),\n",
    "        \"listing_type\": listing_type,\n",
    "        \"listing_date\": listing_date,\n",
    "        \"listing_price\": listing_price,\n",
    "        # listing_status chosen from pool based on listing_type\n",
    "        \"listing_status\": random.choice(status_pool),\n",
    "        \"close_date\": close_date\n",
    "    })\n",
    "\n",
    "df_listings = pd.DataFrame(listings)\n",
    "\n",
    "# SQL insertion to generate listing_id automatically from SERIAL\n",
    "df_listings.to_sql(\"listings\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f887a917-874d-49cb-a54e-1581aa36a2fd",
   "metadata": {
    "id": "f887a917-874d-49cb-a54e-1581aa36a2fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PROPERTY_PRICE_HISTORY FK Data Insertion\n",
    "\n",
    "df_listings_db = pd.read_sql(\n",
    "    \"SELECT listing_id, listing_price, listing_date, close_date \"\n",
    "    \"FROM listings ORDER BY listing_id\",\n",
    "    engine\n",
    ")\n",
    "\n",
    "# PROPERTY_PRICE_HISTORY (200-400 rows)\n",
    "\n",
    "price_history = []\n",
    "\n",
    "for _, row in df_listings_db.iterrows():\n",
    "    listing_id = int(row[\"listing_id\"])\n",
    "    base_price = float(row[\"listing_price\"])\n",
    "    listing_date = pd.to_datetime(row[\"listing_date\"])\n",
    "\n",
    "    close_val = row[\"close_date\"]\n",
    "    # if listing has no close_date yet, default to today\n",
    "    if pd.isna(close_val):\n",
    "        end_dt = pd.Timestamp(\"today\").normalize()\n",
    "    else:\n",
    "        end_dt = pd.to_datetime(close_val)\n",
    "\n",
    "    # safety check in case close_date is earlier than listing_date\n",
    "    if end_dt < listing_date:\n",
    "        end_dt = listing_date\n",
    "\n",
    "    # randomly decide whether this listing has price changes\n",
    "    if random.random() < 0.5:\n",
    "        num_changes = random.randint(1, 3)\n",
    "        current_price = base_price\n",
    "\n",
    "        for _ in range(num_changes):\n",
    "            # generate a valid datetime for the price change between listing and close\n",
    "            if listing_date == end_dt:\n",
    "                change_dt = listing_date\n",
    "            else:\n",
    "                change_dt = fake.date_time_between(\n",
    "                    start_date=listing_date.to_pydatetime(),\n",
    "                    end_date=end_dt.to_pydatetime()\n",
    "                )\n",
    "\n",
    "            # apply a +-10% margin of changes to simulate real pricing strategy changes\n",
    "            factor = random.uniform(0.9, 1.1)\n",
    "            new_price = round(current_price * factor, 2)\n",
    "\n",
    "            # skip change when old and new prices match\n",
    "            if new_price == current_price:\n",
    "                continue\n",
    "\n",
    "            price_history.append({\n",
    "                \"listing_id\": listing_id,\n",
    "                \"old_price\": current_price,\n",
    "                \"new_price\": new_price,\n",
    "                \"change_date\": change_dt,\n",
    "                # reasons mimic common real-estate price-change triggers\n",
    "                \"reason_for_change\": random.choice([\n",
    "                    \"Market feedback\",\n",
    "                    \"Low activity\",\n",
    "                    \"Increased demand\",\n",
    "                    \"Owner adjustment\"\n",
    "                ])\n",
    "            })\n",
    "\n",
    "            # update current_price so subsequent changes build on each other\n",
    "            current_price = new_price\n",
    "\n",
    "df_price_history = pd.DataFrame(price_history)\n",
    "\n",
    "# SQL insertion to generate price_history_id automatically from SERIAL\n",
    "df_price_history.to_sql(\"property_price_history\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe841a4-5282-43f7-97ad-c0a28637f8c5",
   "metadata": {
    "id": "2fe841a4-5282-43f7-97ad-c0a28637f8c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUSTOMERS (200–300 rows)\n",
    "\n",
    "customers = []\n",
    "for _ in range(random.randint(200, 300)):\n",
    "    customers.append({\n",
    "        \"first_name\": fake.first_name(),\n",
    "        \"last_name\": fake.last_name(),\n",
    "        \"email\": fake.unique.email(),\n",
    "        # phone trimmed to 20 chars to fit schema limit\n",
    "        \"phone\": re.sub(r\"[^0-9+()-]\", \"\", fake.phone_number())[:20],\n",
    "        \"address\": fake.street_address(),\n",
    "        \"customer_type\": random.choice([\"buyer\", \"seller\", \"renter\"]),\n",
    "        # created_date kept within last 3 years for pipeline relevance\n",
    "        \"created_date\": fake.date_between(start_date=\"-3y\", end_date=\"today\"),\n",
    "        \"updated_date\": None\n",
    "    })\n",
    "\n",
    "df_customers = pd.DataFrame(customers)\n",
    "\n",
    "# SQL insertion to generate customer_id automatically from SERIAL\n",
    "df_customers.to_sql(\"customers\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "SPIQJqpSr2PA",
   "metadata": {
    "id": "SPIQJqpSr2PA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LEADS FK Data Insertion\n",
    "\n",
    "df_customers_db = pd.read_sql(\n",
    "    \"SELECT customer_id FROM customers ORDER BY customer_id\",\n",
    "    engine\n",
    ")\n",
    "customer_ids = df_customers_db[\"customer_id\"].tolist()\n",
    "\n",
    "# LEADS (250-400 rows)\n",
    "\n",
    "lead_sources = [\"email\", \"digital\", \"print\", \"event\", \"referral\", \"cold_call\"]\n",
    "lead_statuses = [\"active\", \"converted\", \"lost\", \"archived\"]\n",
    "\n",
    "leads = []\n",
    "for _ in range(random.randint(250, 400)):\n",
    "    leads.append({\n",
    "        # customer_id pulled from existing customers\n",
    "        \"customer_id\": random.choice(customer_ids),\n",
    "        # lead_date kept within last 3 years to preserve pipeline relevance\n",
    "        # and remain consistent with customers' data\n",
    "        \"lead_date\": fake.date_between(start_date=\"-3y\", end_date=\"today\"),\n",
    "        \"lead_source\": random.choice(lead_sources),\n",
    "        \"lead_status\": random.choice(lead_statuses),\n",
    "        # est_value 1K to 900K to reflect potential deal values across buyer or seller leads\n",
    "        # this is the potential business value of the lead, not the full property price\n",
    "        \"est_value\": round(random.uniform(1000, 900000), 2),\n",
    "        \"notes\": fake.text(max_nb_chars=200)\n",
    "    })\n",
    "\n",
    "df_leads = pd.DataFrame(leads)\n",
    "\n",
    "# SQL insertion to generate lead_id automatically from SERIAL\n",
    "df_leads.to_sql(\"leads\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dtMv6AVfsIeM",
   "metadata": {
    "id": "dtMv6AVfsIeM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUSTOMER_INTERACTIONS FK Data Insertion\n",
    "\n",
    "df_customers_db = pd.read_sql(\n",
    "    \"SELECT customer_id FROM customers ORDER BY customer_id\",\n",
    "    engine\n",
    ")\n",
    "df_leads_db = pd.read_sql(\n",
    "    \"SELECT lead_id FROM leads ORDER BY lead_id\",\n",
    "    engine\n",
    ")\n",
    "df_listings_db = pd.read_sql(\n",
    "    \"SELECT listing_id FROM listings ORDER BY listing_id\",\n",
    "    engine\n",
    ")\n",
    "\n",
    "customer_ids = df_customers_db[\"customer_id\"].tolist()\n",
    "lead_ids = df_leads_db[\"lead_id\"].tolist()\n",
    "listing_ids = df_listings_db[\"listing_id\"].tolist()\n",
    "\n",
    "# CUSTOMER_INTERACTIONS (400-600 rows)\n",
    "\n",
    "channels = [\"call\", \"email\", \"text\", \"meeting\", \"showing\", \"other\"]\n",
    "\n",
    "interactions = []\n",
    "for _ in range(random.randint(400, 600)):\n",
    "    # lead_id used ~80% of the time, listing_id used ~70% of the time\n",
    "    # this is set to only sometimes because not all interactions are tied to a lead\n",
    "    # and many CRM interactions (calls, emails, follow-ups) are general touchpoints\n",
    "    lead_id_val = random.choice(lead_ids) if random.random() < 0.8 else None\n",
    "    listing_id_val = random.choice(listing_ids) if random.random() < 0.7 else None\n",
    "\n",
    "    interactions.append({\n",
    "        \"customer_id\": random.choice(customer_ids),\n",
    "        \"lead_id\": lead_id_val,\n",
    "        # customer_id chosen from existing customers to keep FK valid\n",
    "        # the time limit is shorter than the other attributes \n",
    "        # because we are expected to have more interactions within one year\n",
    "        \"interaction_dt\": fake.date_time_between(\n",
    "            start_date=\"-1y\", end_date=\"now\"\n",
    "        ),\n",
    "        \"channel\": random.choice(channels),\n",
    "        # subject limited to 120 chars to meet schema safety\n",
    "        \"subject\": fake.sentence(nb_words=6)[:120],\n",
    "        # details uses short text block to represent meeting/call notes\n",
    "        # and to avoid convoluted/unnecessary details\n",
    "        \"details\": fake.text(max_nb_chars=400),\n",
    "        \"listing_id\": listing_id_val,\n",
    "        \"outcome\": random.choice([\n",
    "            \"positive\", \"neutral\", \"negative\",\n",
    "            \"follow_up_needed\", \"no_response\"\n",
    "        ])\n",
    "    })\n",
    "\n",
    "df_interactions = pd.DataFrame(interactions)\n",
    "\n",
    "# SQL insertion to generate interaction_id automatically from SERIAL\n",
    "df_interactions.to_sql(\"customer_interactions\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wD-b4KfdsNOl",
   "metadata": {
    "id": "wD-b4KfdsNOl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OFFERS FK Data Insertion\n",
    "\n",
    "df_customers_db = pd.read_sql(\n",
    "    \"SELECT customer_id FROM customers ORDER BY customer_id\",\n",
    "    engine\n",
    ")\n",
    "df_listings_db = pd.read_sql(\n",
    "    \"SELECT listing_id, listing_price, listing_date FROM listings ORDER BY listing_id\",\n",
    "    engine\n",
    ")\n",
    "df_agents_db = pd.read_sql(\n",
    "    \"SELECT agent_id FROM agents ORDER BY agent_id\",\n",
    "    engine\n",
    ")\n",
    "\n",
    "customer_ids = df_customers_db[\"customer_id\"].tolist()\n",
    "agent_ids = df_agents_db[\"agent_id\"].tolist()\n",
    "\n",
    "# OFFERS (150-250 rows)\n",
    "\n",
    "offer_statuses = [\"submitted\", \"counter\", \"accepted\", \"rejected\", \"expired\"]\n",
    "\n",
    "offers = []\n",
    "for _ in range(random.randint(150, 250)):\n",
    "\n",
    "    # sample a listing to anchor FK and pricing logic\n",
    "    listing_row = df_listings_db.sample(1).iloc[0]\n",
    "    listing_id_val = int(listing_row[\"listing_id\"])\n",
    "    base_price = float(listing_row[\"listing_price\"])\n",
    "    listing_date = pd.to_datetime(listing_row[\"listing_date\"])\n",
    "\n",
    "    # offer_price kept close to listing_price to mimic real negotiations\n",
    "    # works for both rent and sale because it scales from the listing price\n",
    "    factor = random.uniform(0.85, 1.15)\n",
    "    offer_price = round(base_price * factor, 2)\n",
    "\n",
    "    # offer_date must be on or after the listing_date (but not in the future)\n",
    "    offer_date = fake.date_between(\n",
    "        start_date=listing_date.to_pydatetime(),\n",
    "        end_date=\"today\"\n",
    "    )\n",
    "\n",
    "    offers.append({\n",
    "        # customer_id chosen from existing customers\n",
    "        \"customer_id\": random.choice(customer_ids),\n",
    "        # listing_id tied to the listing we sampled above\n",
    "        \"listing_id\": listing_id_val,\n",
    "        # agent_id is assigned about 90 percent of the time since some offers may come in indirectly\n",
    "        \"agent_id\": random.choice(agent_ids) if random.random() < 0.9 else None,\n",
    "        \"offer_price\": offer_price,\n",
    "        # offer_date kept on or after listing_date to maintain temporal consistency\n",
    "        \"offer_date\": offer_date,\n",
    "        \"status\": random.choice(offer_statuses),\n",
    "        # contingencies includes short text to simulate real buyer or renter conditions\n",
    "        \"contingencies\": fake.sentence(nb_words=10)\n",
    "    })\n",
    "\n",
    "df_offers = pd.DataFrame(offers)\n",
    "\n",
    "# SQL insertion to generate offer_id automatically from SERIAL\n",
    "df_offers.to_sql(\"offers\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6nv6mRXwsNW6",
   "metadata": {
    "id": "6nv6mRXwsNW6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONTRACTS FK Data Insertion\n",
    "\n",
    "df_offers_db = pd.read_sql(\n",
    "    \"SELECT offer_id, offer_date FROM offers ORDER BY offer_id\",\n",
    "    engine\n",
    ")\n",
    "\n",
    "offer_ids = df_offers_db[\"offer_id\"].tolist()\n",
    "offer_dates = dict(zip(df_offers_db[\"offer_id\"], df_offers_db[\"offer_date\"]))\n",
    "\n",
    "# CONTRACTS (80-120 rows)\n",
    "\n",
    "contract_types = [\"purchase\", \"lease\", \"listing\"]\n",
    "contract_statuses = [\"pending\", \"active\", \"closed\", \"expired\", \"terminated\"]\n",
    "\n",
    "# contracts cannot exceed number of offers\n",
    "target_n = random.randint(80, 120)\n",
    "n_contracts = min(target_n, len(offer_ids))\n",
    "\n",
    "# sample offer_ids without replacement to satisfy UNIQUE(offer_id)\n",
    "selected_offer_ids = random.sample(offer_ids, n_contracts)\n",
    "\n",
    "contracts = []\n",
    "for oid in selected_offer_ids:\n",
    "    # base_date is the offer_date to make sure it's treated as a date\n",
    "    base_date = pd.to_datetime(offer_dates[oid]).date()\n",
    "\n",
    "    # contract_date must be on or after the offer_date\n",
    "    contract_date = fake.date_between(start_date=base_date, end_date=\"today\")\n",
    "\n",
    "    # signed_date usually exists (~85%), optional to mimic deals that fall through\n",
    "    if random.random() < 0.85:\n",
    "        signed_date = fake.date_between(\n",
    "            start_date=contract_date,\n",
    "            end_date=\"today\"\n",
    "        )\n",
    "    else:\n",
    "        signed_date = None\n",
    "\n",
    "    # expected_close_date often provided (~90%), within 90 days of contract_date\n",
    "    if random.random() < 0.9:\n",
    "        end_limit = contract_date + pd.Timedelta(days=90)\n",
    "        expected_close_date = fake.date_between(\n",
    "            start_date=contract_date,\n",
    "            end_date=end_limit\n",
    "        )\n",
    "    else:\n",
    "        expected_close_date = None\n",
    "\n",
    "    contracts.append({\n",
    "        \"offer_id\": oid,\n",
    "        # contract_type randomized across purchase / lease / listing\n",
    "        \"contract_type\": random.choice(contract_types),\n",
    "        \"contract_date\": contract_date,\n",
    "        \"expected_close_date\": expected_close_date,\n",
    "        \"signed_date\": signed_date,\n",
    "        # status represents full contract lifecycle\n",
    "        \"contract_status\": random.choice(contract_statuses),\n",
    "        \"terms\": fake.text(max_nb_chars=400)\n",
    "    })\n",
    "\n",
    "df_contracts = pd.DataFrame(contracts)\n",
    "\n",
    "# SQL insertion to generate contract_id automatically from SERIAL\n",
    "df_contracts.to_sql(\"contracts\", engine, if_exists=\"append\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
